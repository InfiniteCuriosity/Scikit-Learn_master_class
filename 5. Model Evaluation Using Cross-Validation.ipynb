{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model evaluation using cross-validation\n",
    "In this notebook, we will still use only numerical features.\n",
    "\n",
    "We will discuss the practical aspects of assessing the generalization performance of our model via cross-validation instead of a single train-test split.\n",
    "\n",
    "# Data preparation\n",
    "\n",
    "Let's load the full census data set:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "adult_census = pd.read_csv(\"/Users/russconte/Adult_Census.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will now drop the target from the data we will use to train our predictive model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "target_name = \"Class\"\n",
    "target = adult_census[target_name]\n",
    "data = adult_census.drop(columns=target_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we select only the numerical columns, as seen in the previous notebook."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "   Age  fnlwgt  Education-num  Capital-gain  Capital-loss  Hours-per-week\n0   25  226802              7             0             0              40\n1   38   89814              9             0             0              50\n2   28  336951             12             0             0              40\n3   44  160323             10          7688             0              40\n4   18  103497             10             0             0              30",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>fnlwgt</th>\n      <th>Education-num</th>\n      <th>Capital-gain</th>\n      <th>Capital-loss</th>\n      <th>Hours-per-week</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25</td>\n      <td>226802</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38</td>\n      <td>89814</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28</td>\n      <td>336951</td>\n      <td>12</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>44</td>\n      <td>160323</td>\n      <td>10</td>\n      <td>7688</td>\n      <td>0</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18</td>\n      <td>103497</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_numeric = adult_census.select_dtypes(include=np.number)\n",
    "\n",
    "data_numeric.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now create a model using the make_pipeline tool to chain the preprocessing and the estimator in every iteration of the cross-validation.\n",
    "\n",
    "we will use cross-validation. Cross-validation consists of repeating the procedure such that the training and testing sets are different each time. Generalization performance metrics are collected for each repetition and then aggregated. As a result we can assess the variability of our measure of the model’s generalization performance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In scikit-learn, the function cross_validate allows to do cross-validation and you need to pass it the model, the data, and the target. Since there exists several cross-validation strategies, cross_validate takes a parameter cv which defines the splitting strategy."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 555 ms, sys: 486 ms, total: 1.04 s\n",
      "Wall time: 520 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'fit_time': array([0.06561303, 0.06578612, 0.0674181 , 0.10535502, 0.08446193]),\n 'score_time': array([0.01601005, 0.01569486, 0.01535892, 0.01601887, 0.01655197]),\n 'test_score': array([0.81287747, 0.811342  , 0.81439394, 0.81367731, 0.82258395])}"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "cv_result = cross_validate(model, data_numeric, target, cv=5)\n",
    "cv_result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that by default the cross_validate function discards the K models that were trained on the different overlapping subset of the dataset. The goal of cross-validation is not to train a model, but rather to estimate approximately the generalization performance of a model that would have been trained to the full training set, along with an estimate of the variability (uncertainty on the generalization accuracy)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let’s extract the scores computed on the test fold of each cross-validation round from the cv_result dictionary and compute the mean accuracy and the variation of the accuracy across folds."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean cross-validation accuracy is: 0.815 ± 0.004\n"
     ]
    }
   ],
   "source": [
    "scores = cv_result[\"test_score\"]\n",
    "print(\n",
    "    \"The mean cross-validation accuracy is: \"\n",
    "    f\"{scores.mean():.3f} ± {scores.std():.3f}\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test cross-validation on the Heart data set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "Heart = pd.read_csv(\"/Users/russconte/Heart.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drop the target from the data set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "target = Heart[\"chd\"]\n",
    "Heart = Heart.drop(columns=\"chd\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.9 ms, sys: 17.2 ms, total: 45.1 ms\n",
      "Wall time: 25.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'fit_time': array([0.00453186, 0.00319719, 0.00361514, 0.00311303, 0.00295115]),\n 'score_time': array([0.00091696, 0.0008719 , 0.00087595, 0.00081706, 0.00077486]),\n 'test_score': array([0.74193548, 0.70967742, 0.69565217, 0.7173913 , 0.79347826])}"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "cv_result = cross_validate(model, Heart, target, cv=5)\n",
    "cv_result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean cross-validation accuracy is: 0.732 ± 0.034\n"
     ]
    }
   ],
   "source": [
    "scores = cv_result[\"test_score\"]\n",
    "print(\n",
    "    \"The mean cross-validation accuracy is: \"\n",
    "    f\"{scores.mean():.3f} ± {scores.std():.3f}\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}